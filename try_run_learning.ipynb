{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edacbe48-6f8e-4e3d-a70c-e77be8e8314a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade fsspec s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd24c04-01d4-409c-8000-9c035377ab82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T13:28:07.618133Z",
     "iopub.status.busy": "2024-05-07T13:28:07.617758Z",
     "iopub.status.idle": "2024-05-07T13:28:16.820051Z",
     "shell.execute_reply": "2024-05-07T13:28:16.819413Z",
     "shell.execute_reply.started": "2024-05-07T13:28:07.618112Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: rouge_score>=0.1.2 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: fire>=0.5.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: transformers==4.34.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.34.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: sentencepiece>=0.1.99 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: tokenizers>=0.14.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.14.1)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.29.3)\n",
      "Requirement already satisfied: datasets>=2.14.5 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.14.7)\n",
      "Requirement already satisfied: deepspeed>=0.10.3 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.14.2)\n",
      "Requirement already satisfied: peft>=0.5.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.10.0)\n",
      "Requirement already satisfied: einops>=0.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.8.0)\n",
      "Requirement already satisfied: bitsandbytes==0.41.1 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (0.41.1)\n",
      "Requirement already satisfied: scipy>=1.11.3 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (1.13.0)\n",
      "Collecting protobuf>=4.24.4 (from -r requirements.txt (line 19))\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: torchmetrics>=1.2.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (1.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0->-r requirements.txt (line 5)) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 5)) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 5)) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0->-r requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0->-r requirements.txt (line 5)) (2022.10.31)\n",
      "Requirement already satisfied: requests in /kernel/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0->-r requirements.txt (line 5)) (4.65.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score>=0.1.2->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score>=0.1.2->-r requirements.txt (line 2)) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /kernel/lib/python3.10/site-packages (from rouge_score>=0.1.2->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.5.0->-r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /kernel/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /kernel/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/jupyter/.local/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jupyter/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->-r requirements.txt (line 6)) (12.4.127)\n",
      "Requirement already satisfied: psutil in /kernel/lib/python3.10/site-packages (from accelerate>=0.23.0->-r requirements.txt (line 10)) (5.7.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.5->-r requirements.txt (line 11)) (9.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/jupyter/.local/lib/python3.10/site-packages (from datasets>=2.14.5->-r requirements.txt (line 11)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/jupyter/.local/lib/python3.10/site-packages (from datasets>=2.14.5->-r requirements.txt (line 11)) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/jupyter/.local/lib/python3.10/site-packages (from datasets>=2.14.5->-r requirements.txt (line 11)) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /kernel/fallback/lib/python3.10/site-packages (from datasets>=2.14.5->-r requirements.txt (line 11)) (2.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/jupyter/.local/lib/python3.10/site-packages (from datasets>=2.14.5->-r requirements.txt (line 11)) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.5->-r requirements.txt (line 11)) (3.8.5)\n",
      "Requirement already satisfied: hjson in /home/jupyter/.local/lib/python3.10/site-packages (from deepspeed>=0.10.3->-r requirements.txt (line 12)) (3.1.0)\n",
      "Requirement already satisfied: ninja in /home/jupyter/.local/lib/python3.10/site-packages (from deepspeed>=0.10.3->-r requirements.txt (line 12)) (1.11.1.1)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.10.3->-r requirements.txt (line 12)) (9.0.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.10.3->-r requirements.txt (line 12)) (1.10.12)\n",
      "Requirement already satisfied: pynvml in /kernel/lib/python3.10/site-packages (from deepspeed>=0.10.3->-r requirements.txt (line 12)) (11.5.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/jupyter/.local/lib/python3.10/site-packages (from torchmetrics>=1.2.0->-r requirements.txt (line 20)) (0.11.2)\n",
      "Requirement already satisfied: pretty-errors==1.2.25 in /home/jupyter/.local/lib/python3.10/site-packages (from torchmetrics>=1.2.0->-r requirements.txt (line 20)) (1.2.25)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from pretty-errors==1.2.25->torchmetrics>=1.2.0->-r requirements.txt (line 20)) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /kernel/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.5->-r requirements.txt (line 11)) (23.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /kernel/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.5->-r requirements.txt (line 11)) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->-r requirements.txt (line 11)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->-r requirements.txt (line 11)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->-r requirements.txt (line 11)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->-r requirements.txt (line 11)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.5->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: setuptools in /kernel/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics>=1.2.0->-r requirements.txt (line 20)) (65.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.10/site-packages (from requests->transformers==4.34.0->-r requirements.txt (line 5)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /kernel/lib/python3.10/site-packages (from requests->transformers==4.34.0->-r requirements.txt (line 5)) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.10/site-packages (from requests->transformers==4.34.0->-r requirements.txt (line 5)) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /kernel/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score>=0.1.2->-r requirements.txt (line 2)) (8.1.6)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score>=0.1.2->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /kernel/lib/python3.10/site-packages (from pandas->datasets>=2.14.5->-r requirements.txt (line 11)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.5->-r requirements.txt (line 11)) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.5->-r requirements.txt (line 11)) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.0\n",
      "    Uninstalling protobuf-3.20.0:\n",
      "      Successfully uninstalled protobuf-3.20.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "wandb 0.16.6 requires protobuf!=4.21.0,<5,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 5.26.1 which is incompatible.\n",
      "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "google-cloud-bigquery 3.10.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "google-cloud-bigquery-storage 2.22.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "google-cloud-functions 1.13.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "google-cloud-translate 3.11.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "googleapis-common-protos 1.59.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "grpc-google-iam-v1 0.12.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "proto-plus 1.22.3 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.26.1 which is incompatible.\n",
      "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-5.26.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0681627-1f3c-416d-b277-6797b8ae75a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T22:54:50.389020Z",
     "iopub.status.busy": "2024-05-06T22:54:50.388549Z",
     "iopub.status.idle": "2024-05-06T22:54:55.412700Z",
     "shell.execute_reply": "2024-05-06T22:54:55.411955Z",
     "shell.execute_reply.started": "2024-05-06T22:54:50.388983Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: flash-attn in /home/jupyter/.local/lib/python3.10/site-packages (2.5.8)\n",
      "Requirement already satisfied: torch in /home/jupyter/.local/lib/python3.10/site-packages (from flash-attn) (2.3.0)\n",
      "Requirement already satisfied: einops in /home/jupyter/.local/lib/python3.10/site-packages (from flash-attn) (0.8.0)\n",
      "Requirement already satisfied: packaging in /kernel/lib/python3.10/site-packages (from flash-attn) (24.0)\n",
      "Requirement already satisfied: ninja in /home/jupyter/.local/lib/python3.10/site-packages (from flash-attn) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /kernel/lib/python3.10/site-packages (from torch->flash-attn) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1)\n",
      "Requirement already satisfied: jinja2 in /kernel/lib/python3.10/site-packages (from torch->flash-attn) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/jupyter/.local/lib/python3.10/site-packages (from torch->flash-attn) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jupyter/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /kernel/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e4a42a-22ab-42d7-b0b4-c23ec69075fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:34:02.189056Z",
     "iopub.status.busy": "2024-05-07T19:34:02.188380Z",
     "iopub.status.idle": "2024-05-07T19:34:02.254552Z",
     "shell.execute_reply": "2024-05-07T19:34:02.253874Z",
     "shell.execute_reply.started": "2024-05-07T19:34:02.189027Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad10bdd-a617-46ba-a377-dc55d5fe5cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T13:28:30.202357Z",
     "iopub.status.busy": "2024-05-07T13:28:30.202074Z",
     "iopub.status.idle": "2024-05-07T13:28:32.294593Z",
     "shell.execute_reply": "2024-05-07T13:28:32.293610Z",
     "shell.execute_reply.started": "2024-05-07T13:28:30.202338Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894b8ab7af4e4fffba18a90dbf769485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549117ea3e1e42408fecd9fc07fc62e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70c028adebe48818780a997b8bf56b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4994f15fc74dc49d45e6160fe73fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0f55f6cd294b4da767912564147b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114f0301464241708f8101fc9e3925fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "for a in tqdm(range(5)):\n",
    "    for b in trange(4):\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2de265fa-975d-45bf-b413-ab0561c6a3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T23:53:09.455666Z",
     "iopub.status.busy": "2024-05-06T23:53:09.454777Z",
     "iopub.status.idle": "2024-05-06T23:53:09.467763Z",
     "shell.execute_reply": "2024-05-06T23:53:09.467133Z",
     "shell.execute_reply.started": "2024-05-06T23:53:09.455647Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kek': ['wow, really!', 'ahh pity...'], 'lol': 2} {'kek': ['wow', 'ahh'], 'lol': 2}\n"
     ]
    }
   ],
   "source": [
    "def kek_fn(strings, tokenizer):\n",
    "    return {\n",
    "        \"kek\": strings,\n",
    "        \"lol\": 2,\n",
    "    }\n",
    "\n",
    "sources = [\"wow\", \"ahh\"]\n",
    "examples = [\"wow, really!\", \"ahh pity...\"]\n",
    "examples_tokenized, sources_tokenized = [kek_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "print(examples_tokenized, sources_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "130e49a5-ede8-482f-947c-c69d04e4d0d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:21:02.760403Z",
     "iopub.status.busy": "2024-05-07T12:21:02.759889Z",
     "iopub.status.idle": "2024-05-07T12:21:02.771383Z",
     "shell.execute_reply": "2024-05-07T12:21:02.770803Z",
     "shell.execute_reply.started": "2024-05-07T12:21:02.760383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kek\n"
     ]
    }
   ],
   "source": [
    "print(\"kek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fb0900-cb27-4782-b736-daa71c4e45d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:34:06.141527Z",
     "iopub.status.busy": "2024-05-07T19:34:06.141117Z",
     "iopub.status.idle": "2024-05-07T19:37:25.398631Z",
     "shell.execute_reply": "2024-05-07T19:37:25.397847Z",
     "shell.execute_reply.started": "2024-05-07T19:34:06.141506Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "2024-05-07 19:34:11.779046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import io\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional, Sequence\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "from llama_attn_replace_sft import replace_llama_attn\n",
    "from gptneox_attn_replace import replace_gpt_neox_attn\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.distributed import barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901ca4cb-4d8d-4d6b-a4a3-cbad876b17ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:37:25.400237Z",
     "iopub.status.busy": "2024-05-07T19:37:25.399670Z",
     "iopub.status.idle": "2024-05-07T19:37:25.416031Z",
     "shell.execute_reply": "2024-05-07T19:37:25.415366Z",
     "shell.execute_reply.started": "2024-05-07T19:37:25.400216Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    model_name_or_path: Optional[str] = field(default=\"EleutherAI/pythia-1.4b-deduped\")\n",
    "    model_type: Optional[str] = field(default=\"llama\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    train_data_path: str = field(default=None, metadata={\"help\": \"Path to the training data.\"})\n",
    "    val_data_path: str = field(default=None, metadata={\"help\": \"Path to the validation data.\"})\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingArguments(transformers.TrainingArguments):\n",
    "    cache_dir: Optional[str] = field(default=None)\n",
    "    optim: str = field(default=\"adamw_torch\")\n",
    "    model_max_length: int = field(\n",
    "        default=8192 * 4,\n",
    "        metadata={\"help\": \"Maximum sequence length. Sequences will be right padded (and possibly truncated).\"},\n",
    "    )\n",
    "    use_flash_attn: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether use flash attention for training.\"},\n",
    "    )\n",
    "    use_full_attn: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether to use plain, full-attention for training.\"},\n",
    "    )\n",
    "    low_rank_training: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether use low rank adaptation for training.\"},\n",
    "    )\n",
    "    trainable_params: str = field(\n",
    "        default=\"embed,norm\",\n",
    "        metadata={\"help\": \"Additional trainable parameters except LoRA weights, if low rank training.\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8aa6ef8-49d3-4763-a3dc-5f257966991c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:37:25.417453Z",
     "iopub.status.busy": "2024-05-07T19:37:25.417158Z",
     "iopub.status.idle": "2024-05-07T19:37:25.475280Z",
     "shell.execute_reply": "2024-05-07T19:37:25.474639Z",
     "shell.execute_reply.started": "2024-05-07T19:37:25.417435Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, tokenizer: transformers.PreTrainedTokenizer, use_cache=False):\n",
    "        super(SupervisedDataset, self).__init__()\n",
    "        if not use_cache:\n",
    "            logging.warning(\"Loading data...\")\n",
    "            data_table = pd.read_csv(data_path)\n",
    "\n",
    "            logging.warning(\"Formatting inputs...\")\n",
    "\n",
    "            prompt_input_diploma = PROMPT_DICT[\"prompt_input_diploma_special\"]\n",
    "            sources = [\n",
    "                prompt_input_diploma.format(input=diploma)\n",
    "                for diploma in data_table[\"diploma\"]\n",
    "            ]\n",
    "\n",
    "            targets = [f\"{abstract}{tokenizer.eos_token}\" for abstract in data_table[\"abstract\"]]\n",
    "\n",
    "            logging.warning(\"Tokenizing inputs... This may take some time...\")\n",
    "            data_dict = preprocess(sources, targets, tokenizer)\n",
    "\n",
    "            self.input_ids = data_dict[\"input_ids\"]\n",
    "            self.labels = data_dict[\"labels\"]\n",
    "\n",
    "            self.save_to_disk(data_path)\n",
    "        else:\n",
    "            self.load_from_disk(data_path)\n",
    "            \n",
    "    def get_unique_name(self, data_path):\n",
    "        return data_path.split('/')[-1].split('.')[0]\n",
    "        \n",
    "    def save_to_disk(self, data_path):\n",
    "        unique_name = self.get_unique_name(data_path)\n",
    "        with open(f\"cache/supervised_dataset/{unique_name}_input_ids.json\", \"w\") as f:\n",
    "            json.dump(self.input_ids, f, ensure_ascii=False, indent=2)\n",
    "        with open(f\"cache/supervised_dataset/{unique_name}_labels.json\", \"w\") as f:\n",
    "            json.dump(self.labels, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    def load_from_disk(self, data_path):\n",
    "        unique_name = self.get_unique_name(data_path)\n",
    "        with open(f\"cache/supervised_dataset/{unique_name}_input_ids.json\", \"r\") as f:\n",
    "            self.input_ids = json.load(f)\n",
    "        with open(f\"cache/supervised_dataset/{unique_name}_labels.json\", \"r\") as f:\n",
    "            self.labels = json.load(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b166d74-6eae-4c2d-9e2c-e152abe753d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:37:25.476730Z",
     "iopub.status.busy": "2024-05-07T19:37:25.476167Z",
     "iopub.status.idle": "2024-05-07T19:37:25.511787Z",
     "shell.execute_reply": "2024-05-07T19:37:25.511091Z",
     "shell.execute_reply.started": "2024-05-07T19:37:25.476708Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Written by Yukang Chen\n",
    "# Some code based on https://github.com/epfml/landmark-attention\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "def _make_r_io_base(f, mode: str):\n",
    "    if not isinstance(f, io.IOBase):\n",
    "        f = open(f, mode=mode)\n",
    "    return f\n",
    "\n",
    "def jload(f, mode=\"r\"):\n",
    "    \"\"\"Load a .json file into a dictionary.\"\"\"\n",
    "    f = _make_r_io_base(f, mode)\n",
    "    jdict = json.load(f)\n",
    "    f.close()\n",
    "    return jdict\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input_llama2\":(\n",
    "        \"[INST] <<SYS>>\\n\"\n",
    "        \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\n\"\n",
    "        \"If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n\"\n",
    "        \"<</SYS>> \\n\\n {instruction} [/INST]\"\n",
    "    ),\n",
    "    \"prompt_input_llama2\": (\n",
    "        \"[INST] <<SYS>>\\n\"\n",
    "        \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\n\"\n",
    "        \"If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n\"\n",
    "        \"<</SYS>> \\n\\n {instruction} \\n{input} [/INST]\"\n",
    "    ),\n",
    "    \"prompt_llama2\": \"[INST]{instruction}[/INST]\",\n",
    "    \"prompt_input_diploma_special\":(\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\nBelow is a diploma text. Your task is to generate abstract of this diploma.\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict: Dict,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    model: transformers.PreTrainedModel,\n",
    "):\n",
    "    \"\"\"Resize tokenizer and embedding.\n",
    "\n",
    "    Note: This is the unoptimized version that may make your embedding size not be divisible by 64.\n",
    "    \"\"\"\n",
    "    num_new_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if num_new_tokens > 0:\n",
    "        input_embeddings = model.get_input_embeddings().weight.data\n",
    "        output_embeddings = model.get_output_embeddings().weight.data\n",
    "\n",
    "        input_embeddings_avg = input_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "        output_embeddings_avg = output_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "\n",
    "        input_embeddings[-num_new_tokens:] = input_embeddings_avg\n",
    "        output_embeddings[-num_new_tokens:] = output_embeddings_avg\n",
    "\n",
    "\n",
    "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "    \"\"\"Tokenize a list of strings.\"\"\"\n",
    "    tokenized_list = []\n",
    "    for text in tqdm(strings, desc=\"Texts...\"):\n",
    "        tokenized_list.append(tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "        ))\n",
    "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "    input_ids_lens = labels_lens = [\n",
    "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "    ]\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=labels,\n",
    "        input_ids_lens=input_ids_lens,\n",
    "        labels_lens=labels_lens,\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess(\n",
    "    sources: Sequence[str],\n",
    "    targets: Sequence[str],\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    ") -> Dict:\n",
    "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
    "    examples = [s + t for s, t in zip(sources, targets)]\n",
    "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "    input_ids = examples_tokenized[\"input_ids\"]\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "        label[:source_len] = IGNORE_INDEX\n",
    "    return dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "\n",
    "def make_supervised_data_module(tokenizer: transformers.PreTrainedTokenizer, data_args) -> Dict:\n",
    "    \"\"\"Make dataset and collator for supervised fine-tuning.\"\"\"\n",
    "    train_dataset = SupervisedDataset(tokenizer=tokenizer, data_path=data_args.train_data_path)\n",
    "    val_dataset = SupervisedDataset(tokenizer=tokenizer, data_path=data_args.val_data_path)\n",
    "    data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "    return dict(train_dataset=train_dataset, eval_dataset=val_dataset, data_collator=data_collator)\n",
    "\n",
    "\n",
    "def train(model_args, data_args, training_args):\n",
    "    print(\"Begin train\")\n",
    "    \n",
    "    # NOTE: May expand supported model types in the future\n",
    "    if model_args.model_type == \"gpt-neox\":\n",
    "        replace_gpt_neox_attn(training_args.use_flash_attn, training_args.use_full_attn)\n",
    "    else:\n",
    "        replace_llama_attn(training_args.use_flash_attn, training_args.use_full_attn)\n",
    "\n",
    "    # Set RoPE scaling factor\n",
    "    config = transformers.AutoConfig.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        cache_dir=training_args.cache_dir,\n",
    "    )\n",
    "\n",
    "    orig_rope_scaling = getattr(config, \"rope_scaling\", None)\n",
    "    if orig_rope_scaling is None:\n",
    "        orig_rope_scaling = {\"factor\": 1}\n",
    "    orig_rope_scaling_factor = orig_rope_scaling[\"factor\"] if \"factor\" in orig_rope_scaling.keys() else 1\n",
    "    orig_ctx_len = getattr(config, \"max_position_embeddings\", None)\n",
    "    if orig_ctx_len:\n",
    "        orig_ctx_len *= orig_rope_scaling_factor\n",
    "        if training_args.model_max_length > orig_ctx_len:\n",
    "            scaling_factor = float(math.ceil(training_args.model_max_length / orig_ctx_len))\n",
    "            config.rope_scaling = {\"type\": \"linear\", \"factor\": scaling_factor}\n",
    "            \n",
    "    print(\"Created config\")\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        config=config,\n",
    "        cache_dir=training_args.cache_dir,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    \n",
    "    print(\"Loaded model\")\n",
    "\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        cache_dir=training_args.cache_dir,\n",
    "        model_max_length=training_args.model_max_length,\n",
    "        padding_side=\"right\",\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "    print(\"Loaded tokenizer\")\n",
    "\n",
    "    special_tokens_dict = dict()\n",
    "    if tokenizer.pad_token is None:\n",
    "        special_tokens_dict[\"pad_token\"] = DEFAULT_PAD_TOKEN\n",
    "    if tokenizer.eos_token is None:\n",
    "        special_tokens_dict[\"eos_token\"] = DEFAULT_EOS_TOKEN\n",
    "    if tokenizer.bos_token is None:\n",
    "        special_tokens_dict[\"bos_token\"] = DEFAULT_BOS_TOKEN\n",
    "    if tokenizer.unk_token is None:\n",
    "        special_tokens_dict[\"unk_token\"] = DEFAULT_UNK_TOKEN\n",
    "\n",
    "    smart_tokenizer_and_embedding_resize(\n",
    "        special_tokens_dict=special_tokens_dict,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    data_module = make_supervised_data_module(tokenizer=tokenizer, data_args=data_args)\n",
    "    \n",
    "    print(\"Created data_module\")\n",
    "\n",
    "    if training_args.low_rank_training:\n",
    "        if model_args.model_type == \"gpt-neox\":\n",
    "            # added `dense` to match with llama as the basic LoRA would only target 'query_key_value'\n",
    "            targets = [\"query_key_value\", \"dense\"]\n",
    "        else:\n",
    "            targets=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "\n",
    "        config = LoraConfig(\n",
    "            r=8,\n",
    "            lora_alpha=16,\n",
    "            target_modules=targets,\n",
    "            lora_dropout=0,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "        model = get_peft_model(model, config)\n",
    "        # enable trainable params\n",
    "        [p.requires_grad_() for n, p in model.named_parameters() if any([k in n for k in training_args.trainable_params.split(\",\")])]\n",
    "\n",
    "    model.config.use_cache = False         # required for gradient checkpointing\n",
    "    model.enable_input_require_grads()     # required for gradient checkpointing\n",
    "    model.gradient_checkpointing_enable()  # enable gradient checkpointing\n",
    "    \n",
    "    print(\"Prepared model to learn\")\n",
    "\n",
    "    trainer = Trainer(model=model, tokenizer=tokenizer, args=training_args, **data_module)\n",
    "    trainer.train()\n",
    "    trainer.save_state()\n",
    "    trainer.save_model(output_dir=training_args.output_dir)\n",
    "    \n",
    "    print(\"Learnt model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f244c339-aa5d-45e6-be76-e76c03f0a048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:37:25.512725Z",
     "iopub.status.busy": "2024-05-07T19:37:25.512451Z",
     "iopub.status.idle": "2024-05-07T19:37:25.531657Z",
     "shell.execute_reply": "2024-05-07T19:37:25.531101Z",
     "shell.execute_reply.started": "2024-05-07T19:37:25.512703Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArguments(model_name_or_path='meta-llama/Llama-2-7b-hf', model_type='llama')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args = ModelArguments(model_name_or_path=\"meta-llama/Llama-2-7b-hf\", model_type=\"llama\")\n",
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b713e0-7f2c-4f88-b4f8-b59758ebc2e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:37:25.532545Z",
     "iopub.status.busy": "2024-05-07T19:37:25.532262Z",
     "iopub.status.idle": "2024-05-07T19:37:25.543546Z",
     "shell.execute_reply": "2024-05-07T19:37:25.543005Z",
     "shell.execute_reply.started": "2024-05-07T19:37:25.532515Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataArguments(train_data_path='/home/jupyter/mnt/datasets/diplomas/russian_dataset/russian_dataset_train.csv', val_data_path='/home/jupyter/mnt/datasets/diplomas/russian_dataset/russian_dataset_val.csv')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args = DataArguments(\n",
    "    train_data_path=\"/home/jupyter/mnt/datasets/diplomas/russian_dataset/russian_dataset_train.csv\", \n",
    "    val_data_path=\"/home/jupyter/mnt/datasets/diplomas/russian_dataset/russian_dataset_val.csv\"\n",
    ")\n",
    "data_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925a2812-ef28-4b54-bb6e-135bb20cbe83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:37:25.544395Z",
     "iopub.status.busy": "2024-05-07T19:37:25.544143Z",
     "iopub.status.idle": "2024-05-07T19:37:25.579037Z",
     "shell.execute_reply": "2024-05-07T19:37:25.578511Z",
     "shell.execute_reply.started": "2024-05-07T19:37:25.544377Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir='checkpoints', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=2, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=8, eval_accumulation_steps=None, eval_delay=0, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=5, max_steps=-1, lr_scheduler_type=<SchedulerType.CONSTANT_WITH_WARMUP: 'constant_with_warmup'>, warmup_ratio=0.0, warmup_steps=20, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='checkpoints/runs/May07_19-37-25_g21-2acf8cdd-dfcc-48b0-b2c5-702b8cecfbf8', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=1, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=98, save_total_limit=2, save_safetensors=False, save_on_each_node=False, no_cuda=False, use_cpu=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=True, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=True, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=10, dataloader_num_workers=0, past_index=-1, run_name='checkpoints', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], fsdp=[], fsdp_min_num_params=0, fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}, fsdp_transformer_layer_cls_to_wrap=None, deepspeed='ds_configs/stage2.json', label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_TORCH: 'adamw_torch'>, optim_args=None, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, hub_always_push=False, gradient_checkpointing=False, include_inputs_for_metrics=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, dispatch_batches=None, include_tokens_per_second=False, cache_dir='cache', model_max_length=32768, use_flash_attn=True, use_full_attn=False, low_rank_training=True, trainable_params='embed,norm')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    bf16=True,\n",
    "    output_dir=\"checkpoints\",\n",
    "    cache_dir=\"cache\",\n",
    "    model_max_length=32768,\n",
    "    use_flash_attn=True,\n",
    "    low_rank_training=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=98,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.0,\n",
    "    warmup_steps=20,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    deepspeed=\"ds_configs/stage2.json\",\n",
    "    tf32=True,\n",
    "    report_to=['tensorboard']\n",
    ")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b565d4b6-c7f8-4750-a108-139d4500b0ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:37:25.583988Z",
     "iopub.status.busy": "2024-05-07T19:37:25.582196Z",
     "iopub.status.idle": "2024-05-07T19:37:25.610696Z",
     "shell.execute_reply": "2024-05-07T19:37:25.609996Z",
     "shell.execute_reply.started": "2024-05-07T19:37:25.583964Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaaffcada6b492dbc1b9161c1b8619d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50fbb2c-0064-40a2-a7c8-10cdee729d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:37:25.612004Z",
     "iopub.status.busy": "2024-05-07T19:37:25.611703Z",
     "iopub.status.idle": "2024-05-07T19:37:26.963853Z",
     "shell.execute_reply": "2024-05-07T19:37:26.962737Z",
     "shell.execute_reply.started": "2024-05-07T19:37:25.611983Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin train\n",
      "Created config\n",
      "Loaded tokenizer\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin train\")\n",
    "    \n",
    "# NOTE: May expand supported model types in the future\n",
    "if model_args.model_type == \"gpt-neox\":\n",
    "    replace_gpt_neox_attn(training_args.use_flash_attn, training_args.use_full_attn)\n",
    "else:\n",
    "    replace_llama_attn(training_args.use_flash_attn, training_args.use_full_attn)\n",
    "\n",
    "# Set RoPE scaling factor\n",
    "config = transformers.AutoConfig.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    cache_dir=training_args.cache_dir,\n",
    ")\n",
    "\n",
    "orig_rope_scaling = getattr(config, \"rope_scaling\", None)\n",
    "if orig_rope_scaling is None:\n",
    "    orig_rope_scaling = {\"factor\": 1}\n",
    "orig_rope_scaling_factor = orig_rope_scaling[\"factor\"] if \"factor\" in orig_rope_scaling.keys() else 1\n",
    "orig_ctx_len = getattr(config, \"max_position_embeddings\", None)\n",
    "if orig_ctx_len:\n",
    "    orig_ctx_len *= orig_rope_scaling_factor\n",
    "    if training_args.model_max_length > orig_ctx_len:\n",
    "        scaling_factor = float(math.ceil(training_args.model_max_length / orig_ctx_len))\n",
    "        config.rope_scaling = {\"type\": \"linear\", \"factor\": scaling_factor}\n",
    "\n",
    "print(\"Created config\")\n",
    "\n",
    "# Load tokenizer\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    cache_dir=training_args.cache_dir,\n",
    "    model_max_length=training_args.model_max_length,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=True,\n",
    ")\n",
    "    \n",
    "    \n",
    "print(\"Loaded tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b6e4103-90f2-47fd-ba44-5630c3ceb024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:38:14.201639Z",
     "iopub.status.busy": "2024-05-07T19:38:14.201205Z",
     "iopub.status.idle": "2024-05-07T19:39:08.666445Z",
     "shell.execute_reply": "2024-05-07T19:39:08.665704Z",
     "shell.execute_reply.started": "2024-05-07T19:38:14.201615Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=training_args.cache_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model.to('cuda')\n",
    "\n",
    "print(\"Loaded model\")\n",
    "\n",
    "special_tokens_dict = dict()\n",
    "if tokenizer.pad_token is None:\n",
    "    special_tokens_dict[\"pad_token\"] = DEFAULT_PAD_TOKEN\n",
    "if tokenizer.eos_token is None:\n",
    "    special_tokens_dict[\"eos_token\"] = DEFAULT_EOS_TOKEN\n",
    "if tokenizer.bos_token is None:\n",
    "    special_tokens_dict[\"bos_token\"] = DEFAULT_BOS_TOKEN\n",
    "if tokenizer.unk_token is None:\n",
    "    special_tokens_dict[\"unk_token\"] = DEFAULT_UNK_TOKEN\n",
    "\n",
    "smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict=special_tokens_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f95867-a24d-4c1c-a0ec-7caa3758bc20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:39:08.667969Z",
     "iopub.status.busy": "2024-05-07T19:39:08.667451Z",
     "iopub.status.idle": "2024-05-07T19:39:08.681898Z",
     "shell.execute_reply": "2024-05-07T19:39:08.681262Z",
     "shell.execute_reply.started": "2024-05-07T19:39:08.667939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, tokenizer: transformers.PreTrainedTokenizer, year: int):\n",
    "        super(SupervisedDataset, self).__init__()\n",
    "        logging.warning(f\"Loading data with {year} year...\")\n",
    "        data_table = pd.read_csv(data_path)\n",
    "        data_table = data_table[data_table[\"year\"] == year]\n",
    "        logging.warning(f\"Loaded {len(data_table)} samples\")\n",
    "\n",
    "        logging.warning(\"Formatting inputs...\")\n",
    "\n",
    "        prompt_input_diploma = PROMPT_DICT[\"prompt_input_diploma_special\"]\n",
    "        sources = [\n",
    "            prompt_input_diploma.format(input=diploma)\n",
    "            for diploma in data_table[\"diploma\"]\n",
    "        ]\n",
    "\n",
    "        targets = [f\"{abstract}{tokenizer.eos_token}\" for abstract in data_table[\"abstract\"]]\n",
    "\n",
    "        logging.warning(\"Tokenizing inputs... This may take some time...\")\n",
    "        data_dict = preprocess(sources, targets, tokenizer)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad40998-5411-42d5-9f0c-dfc2e121c315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3dd3ea3-8a1e-4b43-9426-a8a5f87faf50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:39:08.683104Z",
     "iopub.status.busy": "2024-05-07T19:39:08.682826Z",
     "iopub.status.idle": "2024-05-07T19:39:08.701770Z",
     "shell.execute_reply": "2024-05-07T19:39:08.701174Z",
     "shell.execute_reply.started": "2024-05-07T19:39:08.683083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e32ae129a1482fabcd80c814b8c54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdedab8c-e57e-4572-9433-854cd9fc97d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:39:32.731577Z",
     "iopub.status.busy": "2024-05-07T19:39:32.731105Z",
     "iopub.status.idle": "2024-05-07T20:30:12.648838Z",
     "shell.execute_reply": "2024-05-07T20:30:12.648011Z",
     "shell.execute_reply.started": "2024-05-07T19:39:32.731548Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data with 2021 year...\n",
      "WARNING:root:Loaded 1459 samples\n",
      "WARNING:root:Formatting inputs...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d51a79995df4d54a6f05869e2d42be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Texts...:   0%|          | 0/1459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6c9dd6a05e4a3f9954bc0c7fd37528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Texts...:   0%|          | 0/1459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data with 2022 year...\n",
      "WARNING:root:Loaded 1397 samples\n",
      "WARNING:root:Formatting inputs...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485a2d87519645e0ad4a5d4b70fdc9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Texts...:   0%|          | 0/1397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b0e9985ea047ebad635b4bbf5fea0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Texts...:   0%|          | 0/1397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data_module\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SupervisedDataset(tokenizer=tokenizer, data_path=data_args.train_data_path, year=2021)\n",
    "val_dataset = SupervisedDataset(tokenizer=tokenizer, data_path=data_args.val_data_path, year=2022)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "data_module = dict(train_dataset=train_dataset, eval_dataset=val_dataset, data_collator=data_collator)\n",
    "\n",
    "print(\"Created data_module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6bc873d-8ee5-4683-8ed5-5b8ec5c3715f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:30:20.279027Z",
     "iopub.status.busy": "2024-05-07T20:30:20.278444Z",
     "iopub.status.idle": "2024-05-07T20:30:20.525745Z",
     "shell.execute_reply": "2024-05-07T20:30:20.523234Z",
     "shell.execute_reply.started": "2024-05-07T20:30:20.279004Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared model to learn\n"
     ]
    }
   ],
   "source": [
    "if training_args.low_rank_training:\n",
    "    if model_args.model_type == \"gpt-neox\":\n",
    "        # added `dense` to match with llama as the basic LoRA would only target 'query_key_value'\n",
    "        targets = [\"query_key_value\", \"dense\"]\n",
    "    else:\n",
    "        targets=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        target_modules=targets,\n",
    "        lora_dropout=0,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    model = get_peft_model(model, config)\n",
    "    # enable trainable params\n",
    "    [p.requires_grad_() for n, p in model.named_parameters() if any([k in n for k in training_args.trainable_params.split(\",\")])]\n",
    "\n",
    "model.config.use_cache = False         # required for gradient checkpointing\n",
    "model.enable_input_require_grads()     # required for gradient checkpointing\n",
    "model.gradient_checkpointing_enable()  # enable gradient checkpointing\n",
    "\n",
    "print(\"Prepared model to learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2468df4-3ed9-4454-8c1a-b3c1a56e3c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:30:27.370785Z",
     "iopub.status.busy": "2024-05-07T20:30:27.370390Z",
     "iopub.status.idle": "2024-05-07T20:30:27.385983Z",
     "shell.execute_reply": "2024-05-07T20:30:27.385003Z",
     "shell.execute_reply.started": "2024-05-07T20:30:27.370762Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36929304-2553-4397-ab5f-34990b409f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:30:30.550719Z",
     "iopub.status.busy": "2024-05-07T20:30:30.550317Z",
     "iopub.status.idle": "2024-05-07T20:42:18.489514Z",
     "shell.execute_reply": "2024-05-07T20:42:18.488354Z",
     "shell.execute_reply.started": "2024-05-07T20:30:30.550696Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-07 20:30:31,559] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The default cache directory for DeepSpeed Triton autotune, /home/jupyter/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/910 [01:07<17:00:28, 67.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 24.4225, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/910 [02:17<17:20:47, 68.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 72.9774, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/910 [03:23<17:01:17, 67.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 28.833, 'learning_rate': 3e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/910 [04:33<17:16:36, 68.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 14.04, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/910 [05:42<17:17:45, 68.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 16.3768, 'learning_rate': 5e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/910 [06:52<17:23:24, 69.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.7782, 'learning_rate': 6e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/910 [07:58<17:03:00, 67.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 41.9091, 'learning_rate': 7e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/910 [09:04<16:52:55, 67.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4162, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/910 [10:11<16:52:16, 67.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2526, 'learning_rate': 9e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/910 [11:27<17:28:06, 69.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.7221, 'learning_rate': 1e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "\n",
      "  0%|          | 0/699 [00:00<?, ?it/s]\u001b[A/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "\n",
      "  0%|          | 2/699 [00:05<33:59,  2.93s/it]\u001b[A/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "\n",
      "  0%|          | 3/699 [00:11<47:25,  4.09s/it]\u001b[A/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n",
      "/home/jupyter/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py:39: UserWarning: This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\n",
      "  warnings.warn(\"This function should be used just for training as it may exhibit reduced inference performance. For inference, please use forward_flashattn_inference.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5d91e48ec5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1591\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1592\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1982\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2326\u001b[0m                     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3067\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3254\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3255\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3256\u001b[0m             \u001b[0mmain_input_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main_input_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3257\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_input_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3472\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloss_without_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3473\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3474\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3475\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2801\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2802\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   1130\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 )\n\u001b[1;32m    924\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    926\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    636\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/LongLoRA-diploma-research/llama_attn_replace_sft.py\u001b[0m in \u001b[0;36mforward_flashattn\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b s three h d -> b s (three h d)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mx_unpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcu_q_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpad_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mcu_q_len_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcu_q_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mcu_q_len_tmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcu_q_len_tmp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgroup_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/flash_attn/bert_padding.py\u001b[0m in \u001b[0;36munpad_input\u001b[0;34m(hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0mseqlens_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mmax_seqlen_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseqlens_in_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mcu_seqlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqlens_in_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer, args=training_args, **data_module)\n",
    "trainer.train()\n",
    "trainer.save_state()\n",
    "trainer.save_model(output_dir=training_args.output_dir)\n",
    "\n",
    "print(\"Learnt model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf22ee0f-b89a-4bdf-b0fd-5275d0451e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:46:53.390982Z",
     "iopub.status.busy": "2024-05-07T20:46:53.390483Z",
     "iopub.status.idle": "2024-05-07T20:46:53.403552Z",
     "shell.execute_reply": "2024-05-07T20:46:53.402984Z",
     "shell.execute_reply.started": "2024-05-07T20:46:53.390961Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcf3fcde-5397-4a90-aea3-9bed1b4999ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:46:58.650104Z",
     "iopub.status.busy": "2024-05-07T20:46:58.649673Z",
     "iopub.status.idle": "2024-05-07T20:46:58.663730Z",
     "shell.execute_reply": "2024-05-07T20:46:58.663146Z",
     "shell.execute_reply.started": "2024-05-07T20:46:58.650083Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dd3dc6c-adcc-4c92-bad1-7b0760a30f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:47:11.728802Z",
     "iopub.status.busy": "2024-05-07T20:47:11.728409Z",
     "iopub.status.idle": "2024-05-07T20:47:11.756223Z",
     "shell.execute_reply": "2024-05-07T20:47:11.755653Z",
     "shell.execute_reply.started": "2024-05-07T20:47:11.728779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32001, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaLinearScalingRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32001, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85c81097-3674-4d41-806a-303e54a67c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:46:24.871344Z",
     "iopub.status.busy": "2024-05-07T20:46:24.870959Z",
     "iopub.status.idle": "2024-05-07T20:46:24.887409Z",
     "shell.execute_reply": "2024-05-07T20:46:24.886835Z",
     "shell.execute_reply.started": "2024-05-07T20:46:24.871320Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff000bfb-3d47-4b18-8a10-4984c64aa1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:51:15.788677Z",
     "iopub.status.busy": "2024-05-07T20:51:15.788233Z",
     "iopub.status.idle": "2024-05-07T20:51:15.826148Z",
     "shell.execute_reply": "2024-05-07T20:51:15.825183Z",
     "shell.execute_reply.started": "2024-05-07T20:51:15.788653Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cuda'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e8f996d25de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A list of colors: red, blue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([\"A list of colors: red, blue\"], return_tensors=\"pt\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfea1c72-7010-412c-b551-4a40530fecfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:52:43.783945Z",
     "iopub.status.busy": "2024-05-07T20:52:43.783521Z",
     "iopub.status.idle": "2024-05-07T20:52:44.107476Z",
     "shell.execute_reply": "2024-05-07T20:52:44.106458Z",
     "shell.execute_reply.started": "2024-05-07T20:52:43.783920Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-8dc084128536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9942308f-30bc-47f8-b2b1-0ff1e2fc95e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:50:40.294953Z",
     "iopub.status.busy": "2024-05-07T20:50:40.294594Z",
     "iopub.status.idle": "2024-05-07T20:50:40.325882Z",
     "shell.execute_reply": "2024-05-07T20:50:40.325231Z",
     "shell.execute_reply.started": "2024-05-07T20:50:40.294931Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32001, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaLinearScalingRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32001, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d84f3-e827-4732-aa75-054c156ba875",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(**model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4186759-0bf6-488b-8c62-e2cc56857325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:47:24.382709Z",
     "iopub.status.busy": "2024-05-07T20:47:24.382078Z",
     "iopub.status.idle": "2024-05-07T20:47:24.426522Z",
     "shell.execute_reply": "2024-05-07T20:47:24.425671Z",
     "shell.execute_reply.started": "2024-05-07T20:47:24.382684Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-524126eae054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A list of colors: red, blue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgenerated_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([\"A list of colors: red, blue\"], return_tensors=\"pt\").to(device)\n",
    "generated_ids = model.generate(**model_inputs)\n",
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5d6d255-7a83-4b36-adbc-19c48916d4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T20:43:35.385836Z",
     "iopub.status.busy": "2024-05-07T20:43:35.385260Z",
     "iopub.status.idle": "2024-05-07T20:43:35.433277Z",
     "shell.execute_reply": "2024-05-07T20:43:35.432282Z",
     "shell.execute_reply.started": "2024-05-07T20:43:35.385814Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d411bda354cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kek\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   1130\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "model(\"kek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c30429e5-cd3e-4a2f-bef0-26a5a96d6bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T17:32:18.219875Z",
     "iopub.status.busy": "2024-05-07T17:32:18.219454Z",
     "iopub.status.idle": "2024-05-07T17:33:23.620629Z",
     "shell.execute_reply": "2024-05-07T17:33:23.619889Z",
     "shell.execute_reply.started": "2024-05-07T17:32:18.219854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32001, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32001, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import peft\n",
    "\n",
    "learnt_model = peft.AutoPeftModelForCausalLM.from_pretrained(training_args.output_dir)\n",
    "learnt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6229ea3a-c5e7-4a57-8785-1a91104db5ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T15:57:25.780233Z",
     "iopub.status.busy": "2024-05-07T15:57:25.779826Z",
     "iopub.status.idle": "2024-05-07T15:58:00.309385Z",
     "shell.execute_reply": "2024-05-07T15:58:00.308592Z",
     "shell.execute_reply.started": "2024-05-07T15:57:25.780211Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading config.json: 100%|██████████| 609/609 [00:00<00:00, 3.48MB/s]\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "adapter_model.bin:   0%|          | 0.00/541M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "training_args.bin:   0%|          | 0.00/5.88k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   0%|          | 8.19k/541M [00:00<7:13:46, 20.8kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.model:   2%|▏         | 8.19k/500k [00:00<00:24, 20.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "training_args.bin: 100%|██████████| 5.88k/5.88k [00:00<00:00, 14.6kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   0%|          | 328k/541M [00:00<11:22, 792kB/s]    \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "training_args.bin: 100%|██████████| 5.88k/5.88k [00:00<00:00, 9.21kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "adapter_model.bin:   1%|          | 2.89M/541M [00:00<01:21, 6.62MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   1%|          | 5.91M/541M [00:00<00:46, 11.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tokenizer.model: 100%|██████████| 500k/500k [00:01<00:00, 430kB/s]B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "adapter_model.bin:   2%|▏         | 12.6M/541M [00:01<00:35, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   3%|▎         | 16.0M/541M [00:01<00:55, 9.48MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   4%|▍         | 22.6M/541M [00:01<00:32, 16.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   5%|▍         | 26.8M/541M [00:02<00:38, 13.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   5%|▌         | 28.8M/541M [00:02<00:37, 13.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   6%|▌         | 30.8M/541M [00:02<00:35, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   6%|▌         | 32.6M/541M [00:03<00:54, 9.39MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   7%|▋         | 38.6M/541M [00:03<00:31, 16.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   8%|▊         | 43.2M/541M [00:03<00:40, 12.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   8%|▊         | 45.4M/541M [00:03<00:37, 13.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   9%|▉         | 47.5M/541M [00:03<00:34, 14.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:   9%|▉         | 49.6M/541M [00:04<00:54, 9.02MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  10%|█         | 55.1M/541M [00:04<00:34, 14.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  11%|█         | 59.6M/541M [00:05<00:40, 11.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  11%|█▏        | 61.5M/541M [00:05<00:38, 12.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  12%|█▏        | 64.0M/541M [00:05<01:02, 7.66MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  13%|█▎        | 69.7M/541M [00:06<00:38, 12.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  14%|█▍        | 75.2M/541M [00:06<00:40, 11.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  14%|█▍        | 77.1M/541M [00:06<00:38, 12.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  15%|█▍        | 80.0M/541M [00:07<00:48, 9.58MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  16%|█▌        | 87.3M/541M [00:07<00:29, 15.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  17%|█▋        | 90.9M/541M [00:07<00:35, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  17%|█▋        | 92.8M/541M [00:07<00:33, 13.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  17%|█▋        | 94.6M/541M [00:07<00:32, 13.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  18%|█▊        | 96.4M/541M [00:08<00:49, 8.95MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  19%|█▉        | 104M/541M [00:08<00:27, 16.1MB/s] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  20%|█▉        | 107M/541M [00:09<00:36, 12.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  20%|██        | 109M/541M [00:09<00:34, 12.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  21%|██        | 112M/541M [00:09<00:49, 8.65MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  22%|██▏       | 121M/541M [00:09<00:25, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  24%|██▎       | 128M/541M [00:10<00:23, 17.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  25%|██▌       | 136M/541M [00:10<00:16, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  27%|██▋       | 144M/541M [00:10<00:12, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  28%|██▊       | 149M/541M [00:10<00:15, 25.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  29%|██▊       | 155M/541M [00:11<00:20, 18.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  29%|██▉       | 159M/541M [00:11<00:19, 19.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  30%|██▉       | 162M/541M [00:12<00:28, 13.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  31%|███▏      | 170M/541M [00:12<00:18, 20.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  33%|███▎      | 176M/541M [00:12<00:17, 21.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  34%|███▍      | 184M/541M [00:12<00:12, 29.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  35%|███▌      | 192M/541M [00:12<00:13, 26.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  37%|███▋      | 200M/541M [00:12<00:10, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  38%|███▊      | 208M/541M [00:13<00:11, 28.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  40%|███▉      | 215M/541M [00:13<00:09, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  41%|████▏     | 224M/541M [00:13<00:07, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  42%|████▏     | 230M/541M [00:13<00:10, 29.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  43%|████▎     | 235M/541M [00:14<00:15, 20.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  44%|████▍     | 239M/541M [00:14<00:14, 21.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  45%|████▍     | 242M/541M [00:15<00:20, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  46%|████▌     | 247M/541M [00:15<00:16, 17.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  46%|████▋     | 252M/541M [00:15<00:21, 13.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  47%|████▋     | 254M/541M [00:15<00:19, 14.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  47%|████▋     | 256M/541M [00:16<00:31, 9.04MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  49%|████▊     | 263M/541M [00:16<00:18, 15.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  50%|█████     | 271M/541M [00:16<00:12, 22.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  51%|█████     | 276M/541M [00:16<00:12, 21.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  52%|█████▏    | 282M/541M [00:17<00:09, 28.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  53%|█████▎    | 288M/541M [00:17<00:10, 23.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  55%|█████▍    | 296M/541M [00:17<00:07, 31.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  56%|█████▌    | 304M/541M [00:17<00:09, 25.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  58%|█████▊    | 313M/541M [00:18<00:06, 33.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  59%|█████▉    | 320M/541M [00:18<00:10, 21.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  61%|██████    | 328M/541M [00:18<00:07, 28.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  62%|██████▏   | 336M/541M [00:19<00:08, 25.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  64%|██████▎   | 344M/541M [00:19<00:05, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  65%|██████▌   | 352M/541M [00:19<00:07, 26.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  67%|██████▋   | 360M/541M [00:19<00:05, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  68%|██████▊   | 368M/541M [00:20<00:05, 30.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  70%|██████▉   | 377M/541M [00:20<00:04, 38.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  71%|███████   | 384M/541M [00:20<00:05, 30.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  72%|███████▏  | 391M/541M [00:20<00:04, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  73%|███████▎  | 397M/541M [00:21<00:06, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  74%|███████▍  | 401M/541M [00:21<00:09, 15.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  76%|███████▌  | 410M/541M [00:21<00:05, 22.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  77%|███████▋  | 416M/541M [00:22<00:05, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  78%|███████▊  | 424M/541M [00:22<00:04, 28.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  80%|███████▉  | 432M/541M [00:22<00:04, 27.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  81%|████████▏ | 440M/541M [00:22<00:02, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  83%|████████▎ | 448M/541M [00:23<00:03, 29.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  84%|████████▍ | 456M/541M [00:23<00:02, 37.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  86%|████████▌ | 464M/541M [00:23<00:02, 30.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  87%|████████▋ | 473M/541M [00:23<00:01, 39.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  89%|████████▊ | 480M/541M [00:24<00:02, 28.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  90%|█████████ | 488M/541M [00:24<00:01, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  92%|█████████▏| 496M/541M [00:24<00:01, 29.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  93%|█████████▎| 505M/541M [00:24<00:00, 37.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  95%|█████████▍| 512M/541M [00:25<00:00, 29.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  96%|█████████▌| 520M/541M [00:25<00:00, 32.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  97%|█████████▋| 525M/541M [00:25<00:00, 22.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin:  98%|█████████▊| 528M/541M [00:26<00:00, 14.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "adapter_model.bin: 100%|██████████| 541M/541M [00:26<00:00, 20.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Upload 3 LFS files: 100%|██████████| 3/3 [00:27<00:00,  9.12s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/nvdenisov2002/llama-longLoRA-v0/tree/main/'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f3746-7301-48f5-a787-3b2e965d6f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27a8fb-572b-44fe-9ad8-e3633fb8f721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07dfcc5-0451-4d46-b143-eacea00a8571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93d126-9ba3-4ada-a220-9c31c11af873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17d9d882-ae7f-4402-9104-59c52401f46a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T21:01:44.132693Z",
     "iopub.status.busy": "2024-05-07T21:01:44.132240Z",
     "iopub.status.idle": "2024-05-07T21:06:53.688424Z",
     "shell.execute_reply": "2024-05-07T21:06:53.687078Z",
     "shell.execute_reply.started": "2024-05-07T21:01:44.132672Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloading adapter_config.json: 100%|██████████| 674/674 [00:00<00:00, 2.13MB/s]\n",
      "\n",
      "\n",
      "Downloading config.json: 100%|██████████| 609/609 [00:00<00:00, 5.02MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 7.15MB/s]\n",
      "\n",
      "\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 10.5M/9.98G [00:00<07:05, 23.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 21.0M/9.98G [00:00<05:15, 31.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 31.5M/9.98G [00:00<04:20, 38.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 41.9M/9.98G [00:01<03:31, 47.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 52.4M/9.98G [00:01<03:08, 52.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 62.9M/9.98G [00:01<02:53, 57.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 73.4M/9.98G [00:01<02:46, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 83.9M/9.98G [00:01<02:37, 62.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 94.4M/9.98G [00:01<02:32, 64.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 105M/9.98G [00:01<02:28, 66.4MB/s] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 115M/9.98G [00:02<02:26, 67.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|▏         | 126M/9.98G [00:02<02:24, 68.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|▏         | 136M/9.98G [00:02<02:23, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   1%|▏         | 147M/9.98G [00:02<02:22, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 157M/9.98G [00:02<02:21, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 168M/9.98G [00:02<02:21, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 178M/9.98G [00:03<02:20, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 189M/9.98G [00:03<02:20, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 199M/9.98G [00:03<02:20, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 210M/9.98G [00:03<02:20, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 220M/9.98G [00:03<02:20, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 231M/9.98G [00:03<02:20, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 241M/9.98G [00:03<02:20, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 252M/9.98G [00:04<02:19, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 262M/9.98G [00:04<02:19, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 273M/9.98G [00:04<02:18, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 283M/9.98G [00:04<02:18, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 294M/9.98G [00:04<02:18, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 304M/9.98G [00:04<02:17, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 315M/9.98G [00:04<02:17, 70.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 325M/9.98G [00:05<02:17, 70.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 336M/9.98G [00:05<02:17, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 346M/9.98G [00:05<02:17, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   4%|▎         | 357M/9.98G [00:05<02:17, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   4%|▎         | 367M/9.98G [00:05<02:16, 70.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 377M/9.98G [00:05<02:16, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 388M/9.98G [00:06<02:16, 70.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 398M/9.98G [00:06<02:17, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 409M/9.98G [00:06<02:17, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 419M/9.98G [00:06<02:17, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 430M/9.98G [00:06<02:17, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 440M/9.98G [00:06<02:17, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 451M/9.98G [00:06<02:17, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 461M/9.98G [00:07<02:16, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 472M/9.98G [00:07<02:16, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 482M/9.98G [00:07<02:16, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 493M/9.98G [00:07<02:16, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 503M/9.98G [00:07<02:15, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 514M/9.98G [00:07<02:15, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 524M/9.98G [00:07<02:15, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 535M/9.98G [00:08<02:15, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 545M/9.98G [00:08<02:15, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 556M/9.98G [00:08<02:15, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 566M/9.98G [00:08<02:15, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 577M/9.98G [00:08<02:15, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 587M/9.98G [00:08<02:15, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 598M/9.98G [00:09<02:15, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 608M/9.98G [00:09<02:15, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 619M/9.98G [00:09<02:15, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   6%|▋         | 629M/9.98G [00:09<02:14, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   6%|▋         | 640M/9.98G [00:09<02:14, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 650M/9.98G [00:09<02:14, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 661M/9.98G [00:09<02:14, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 671M/9.98G [00:10<02:14, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 682M/9.98G [00:10<02:14, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 692M/9.98G [00:10<02:14, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 703M/9.98G [00:10<02:13, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 713M/9.98G [00:10<02:13, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 724M/9.98G [00:10<02:18, 67.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 734M/9.98G [00:11<02:23, 64.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 744M/9.98G [00:11<02:32, 60.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 755M/9.98G [00:11<02:26, 63.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 765M/9.98G [00:11<02:21, 64.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 776M/9.98G [00:11<02:18, 66.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 786M/9.98G [00:11<02:16, 67.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 797M/9.98G [00:11<02:14, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 807M/9.98G [00:12<02:13, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 818M/9.98G [00:12<02:13, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 828M/9.98G [00:12<02:12, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 839M/9.98G [00:12<02:12, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▊         | 849M/9.98G [00:12<02:11, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▊         | 860M/9.98G [00:12<02:11, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▊         | 870M/9.98G [00:13<02:10, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 881M/9.98G [00:13<02:10, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 891M/9.98G [00:13<02:10, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 902M/9.98G [00:13<02:10, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 912M/9.98G [00:13<02:09, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 923M/9.98G [00:13<02:09, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 933M/9.98G [00:13<02:09, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 944M/9.98G [00:14<02:09, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 954M/9.98G [00:14<02:09, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 965M/9.98G [00:14<02:08, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 975M/9.98G [00:14<02:08, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 986M/9.98G [00:14<02:08, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 996M/9.98G [00:14<02:08, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 1.01G/9.98G [00:15<02:08, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 1.02G/9.98G [00:15<02:08, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 1.03G/9.98G [00:15<02:08, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 1.04G/9.98G [00:15<02:07, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.05G/9.98G [00:15<02:07, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.06G/9.98G [00:15<02:07, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.07G/9.98G [00:15<02:07, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.08G/9.98G [00:16<02:07, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.09G/9.98G [00:16<02:06, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.10G/9.98G [00:16<02:06, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.11G/9.98G [00:16<02:06, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.12G/9.98G [00:16<02:06, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█▏        | 1.13G/9.98G [00:16<02:06, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  11%|█▏        | 1.14G/9.98G [00:16<02:06, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.15G/9.98G [00:17<02:06, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.16G/9.98G [00:17<02:05, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.17G/9.98G [00:17<02:05, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.18G/9.98G [00:17<02:06, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.20G/9.98G [00:17<03:10, 46.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.21G/9.98G [00:18<02:51, 51.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.22G/9.98G [00:18<02:38, 55.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.23G/9.98G [00:18<02:28, 58.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.24G/9.98G [00:18<02:21, 61.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.25G/9.98G [00:18<02:16, 64.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.26G/9.98G [00:18<02:12, 65.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.27G/9.98G [00:19<02:09, 67.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.28G/9.98G [00:19<02:08, 67.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.29G/9.98G [00:19<02:06, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.30G/9.98G [00:19<02:05, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.31G/9.98G [00:19<02:05, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.32G/9.98G [00:19<02:04, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.33G/9.98G [00:19<02:04, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.34G/9.98G [00:20<02:03, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  14%|█▎        | 1.35G/9.98G [00:20<02:03, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  14%|█▎        | 1.36G/9.98G [00:20<02:03, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.37G/9.98G [00:20<02:03, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.38G/9.98G [00:20<02:03, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.39G/9.98G [00:20<02:02, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.41G/9.98G [00:20<02:02, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.42G/9.98G [00:21<02:02, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.43G/9.98G [00:21<02:02, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.44G/9.98G [00:21<02:02, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.45G/9.98G [00:21<02:02, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.46G/9.98G [00:21<02:02, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.47G/9.98G [00:21<02:02, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.48G/9.98G [00:22<02:01, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.49G/9.98G [00:22<02:01, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.50G/9.98G [00:22<02:01, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.51G/9.98G [00:22<02:04, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.52G/9.98G [00:22<02:04, 67.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.53G/9.98G [00:22<02:03, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.54G/9.98G [00:22<02:02, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.55G/9.98G [00:23<02:02, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.56G/9.98G [00:23<02:01, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.57G/9.98G [00:23<02:01, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.58G/9.98G [00:23<02:00, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.59G/9.98G [00:23<02:00, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.60G/9.98G [00:23<01:59, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.61G/9.98G [00:23<01:59, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  16%|█▋        | 1.63G/9.98G [00:24<01:59, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  16%|█▋        | 1.64G/9.98G [00:24<01:58, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.65G/9.98G [00:24<01:58, 70.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.66G/9.98G [00:24<01:58, 70.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.67G/9.98G [00:24<01:58, 70.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.68G/9.98G [00:24<01:58, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.69G/9.98G [00:25<01:58, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.70G/9.98G [00:25<01:58, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.71G/9.98G [00:25<01:58, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.72G/9.98G [00:25<01:58, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.73G/9.98G [00:25<01:58, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.74G/9.98G [00:25<01:58, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.75G/9.98G [00:25<01:58, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.76G/9.98G [00:26<01:58, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.77G/9.98G [00:26<01:57, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.78G/9.98G [00:26<01:57, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.79G/9.98G [00:26<01:57, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.80G/9.98G [00:26<01:57, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.81G/9.98G [00:26<01:56, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.82G/9.98G [00:26<01:57, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.84G/9.98G [00:27<01:56, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.85G/9.98G [00:27<01:56, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  19%|█▊        | 1.86G/9.98G [00:27<01:56, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  19%|█▊        | 1.87G/9.98G [00:27<01:56, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.88G/9.98G [00:27<01:56, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.89G/9.98G [00:27<01:56, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.90G/9.98G [00:28<01:55, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.91G/9.98G [00:28<01:57, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.92G/9.98G [00:28<01:56, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.93G/9.98G [00:28<01:56, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.94G/9.98G [00:28<01:55, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.95G/9.98G [00:28<01:55, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.96G/9.98G [00:28<01:54, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.97G/9.98G [00:29<01:54, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.98G/9.98G [00:29<01:54, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.99G/9.98G [00:29<01:54, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.00G/9.98G [00:29<01:54, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.01G/9.98G [00:29<01:54, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.02G/9.98G [00:29<01:54, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.03G/9.98G [00:30<01:54, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.04G/9.98G [00:30<01:53, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.06G/9.98G [00:30<01:53, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.07G/9.98G [00:30<01:53, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.08G/9.98G [00:30<01:53, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.09G/9.98G [00:30<01:53, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.10G/9.98G [00:30<01:52, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.11G/9.98G [00:31<01:52, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.12G/9.98G [00:31<01:52, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  21%|██▏       | 2.13G/9.98G [00:31<01:52, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  21%|██▏       | 2.14G/9.98G [00:31<01:52, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.15G/9.98G [00:31<01:51, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.16G/9.98G [00:31<01:52, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.17G/9.98G [00:31<01:51, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.18G/9.98G [00:32<01:51, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.19G/9.98G [00:32<01:51, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.20G/9.98G [00:32<01:51, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.21G/9.98G [00:32<01:51, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.22G/9.98G [00:32<01:51, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.23G/9.98G [00:32<01:50, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.24G/9.98G [00:33<01:50, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.25G/9.98G [00:33<01:50, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.26G/9.98G [00:33<01:50, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.28G/9.98G [00:33<01:50, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.29G/9.98G [00:33<01:50, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.30G/9.98G [00:33<01:49, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.31G/9.98G [00:33<01:49, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.32G/9.98G [00:34<01:49, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.33G/9.98G [00:34<01:50, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.34G/9.98G [00:34<01:49, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▎       | 2.35G/9.98G [00:34<01:50, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▎       | 2.36G/9.98G [00:34<01:50, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.37G/9.98G [00:34<01:50, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.38G/9.98G [00:34<01:50, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.39G/9.98G [00:35<01:50, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.40G/9.98G [00:35<01:49, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.41G/9.98G [00:35<01:50, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.42G/9.98G [00:35<01:49, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.43G/9.98G [00:35<01:49, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.44G/9.98G [00:35<01:49, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.45G/9.98G [00:36<01:49, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.46G/9.98G [00:36<01:48, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.47G/9.98G [00:36<01:48, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.49G/9.98G [00:36<01:48, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.50G/9.98G [00:36<01:48, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.51G/9.98G [00:36<01:48, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.52G/9.98G [00:36<01:48, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.53G/9.98G [00:37<01:49, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.54G/9.98G [00:37<01:48, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.55G/9.98G [00:37<01:48, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.56G/9.98G [00:37<01:48, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.57G/9.98G [00:37<01:47, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.58G/9.98G [00:37<01:47, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.59G/9.98G [00:38<01:47, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.60G/9.98G [00:38<01:47, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.61G/9.98G [00:38<01:47, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▋       | 2.62G/9.98G [00:38<01:47, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▋       | 2.63G/9.98G [00:38<01:47, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  26%|██▋       | 2.64G/9.98G [00:38<01:46, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.65G/9.98G [00:38<01:46, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.66G/9.98G [00:39<01:46, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.67G/9.98G [00:39<01:45, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.68G/9.98G [00:39<01:45, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.69G/9.98G [00:39<01:44, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.71G/9.98G [00:39<01:45, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.72G/9.98G [00:39<01:44, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.73G/9.98G [00:40<01:44, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.74G/9.98G [00:40<01:45, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.75G/9.98G [00:40<01:44, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.76G/9.98G [00:40<01:44, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.77G/9.98G [00:40<01:44, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.78G/9.98G [00:40<01:44, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.79G/9.98G [00:40<01:44, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.80G/9.98G [00:41<01:43, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.81G/9.98G [00:41<01:43, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.82G/9.98G [00:41<01:42, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.83G/9.98G [00:41<01:42, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.84G/9.98G [00:41<01:42, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  29%|██▊       | 2.85G/9.98G [00:41<01:42, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  29%|██▊       | 2.86G/9.98G [00:41<01:42, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.87G/9.98G [00:42<01:42, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.88G/9.98G [00:42<01:42, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.89G/9.98G [00:42<01:42, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.90G/9.98G [00:42<01:42, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.92G/9.98G [00:42<01:42, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.93G/9.98G [00:42<01:41, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.94G/9.98G [00:43<01:42, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.95G/9.98G [00:43<01:41, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.96G/9.98G [00:43<01:41, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.97G/9.98G [00:43<01:40, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.98G/9.98G [00:43<01:40, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.99G/9.98G [00:43<01:40, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.00G/9.98G [00:43<01:39, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.01G/9.98G [00:44<01:39, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.02G/9.98G [00:44<01:40, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.03G/9.98G [00:44<01:39, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.04G/9.98G [00:44<01:39, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.05G/9.98G [00:44<01:39, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.06G/9.98G [00:44<01:39, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.07G/9.98G [00:44<01:38, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.08G/9.98G [00:45<01:38, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.09G/9.98G [00:45<01:38, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.10G/9.98G [00:45<01:38, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.11G/9.98G [00:45<01:38, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  31%|███▏      | 3.12G/9.98G [00:45<01:38, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  31%|███▏      | 3.14G/9.98G [00:45<01:38, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.15G/9.98G [00:46<01:37, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.16G/9.98G [00:46<01:37, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.17G/9.98G [00:46<01:37, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.18G/9.98G [00:46<01:37, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.19G/9.98G [00:46<01:37, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.20G/9.98G [00:46<01:37, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.21G/9.98G [00:46<01:37, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.22G/9.98G [00:47<01:36, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.23G/9.98G [00:47<01:36, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.24G/9.98G [00:47<01:36, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.25G/9.98G [00:47<01:36, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.26G/9.98G [00:47<01:36, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.27G/9.98G [00:47<01:36, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.28G/9.98G [00:47<01:36, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.29G/9.98G [00:48<01:36, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.30G/9.98G [00:48<01:35, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.31G/9.98G [00:48<01:35, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.32G/9.98G [00:48<01:35, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.33G/9.98G [00:48<01:35, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▎      | 3.34G/9.98G [00:48<01:35, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▎      | 3.36G/9.98G [00:49<01:35, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▎      | 3.37G/9.98G [00:49<01:34, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.38G/9.98G [00:49<01:34, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.39G/9.98G [00:49<01:35, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.40G/9.98G [00:49<01:34, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.41G/9.98G [00:49<01:34, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.42G/9.98G [00:49<01:34, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.43G/9.98G [00:50<01:34, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.44G/9.98G [00:50<01:33, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.45G/9.98G [00:50<02:20, 46.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.46G/9.98G [00:50<02:06, 51.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.47G/9.98G [00:50<01:56, 55.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.48G/9.98G [00:51<01:49, 59.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.49G/9.98G [00:51<01:44, 62.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.50G/9.98G [00:51<01:40, 64.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.51G/9.98G [00:51<01:38, 65.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.52G/9.98G [00:51<01:36, 67.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.53G/9.98G [00:51<01:35, 67.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.54G/9.98G [00:52<01:34, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.55G/9.98G [00:52<01:33, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.57G/9.98G [00:52<01:32, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.58G/9.98G [00:52<01:32, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.59G/9.98G [00:52<01:32, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.60G/9.98G [00:52<01:32, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.61G/9.98G [00:52<01:31, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▋      | 3.62G/9.98G [00:53<01:31, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▋      | 3.63G/9.98G [00:53<01:31, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  36%|███▋      | 3.64G/9.98G [00:53<01:31, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.65G/9.98G [00:53<01:31, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.66G/9.98G [00:53<01:31, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.67G/9.98G [00:53<01:30, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.68G/9.98G [00:53<01:30, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.69G/9.98G [00:54<01:30, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.70G/9.98G [00:54<01:29, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.71G/9.98G [00:54<01:30, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.72G/9.98G [00:54<01:29, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.73G/9.98G [00:54<01:29, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.74G/9.98G [00:54<01:29, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.75G/9.98G [00:55<01:29, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.76G/9.98G [00:55<01:29, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.77G/9.98G [00:55<01:28, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.79G/9.98G [00:55<01:28, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.80G/9.98G [00:55<01:28, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.81G/9.98G [00:55<01:28, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.82G/9.98G [00:55<01:28, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.83G/9.98G [00:56<01:28, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.84G/9.98G [00:56<01:28, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  39%|███▊      | 3.85G/9.98G [00:56<01:28, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  39%|███▊      | 3.86G/9.98G [00:56<01:28, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.87G/9.98G [00:56<01:28, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.88G/9.98G [00:56<01:27, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.89G/9.98G [00:56<01:27, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.90G/9.98G [00:57<01:27, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.91G/9.98G [00:57<01:27, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.92G/9.98G [00:57<01:27, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.93G/9.98G [00:57<01:27, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.94G/9.98G [00:57<01:27, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.95G/9.98G [00:57<01:26, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.96G/9.98G [00:58<01:26, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.97G/9.98G [00:58<01:26, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.98G/9.98G [00:58<01:26, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.00G/9.98G [00:58<01:26, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.01G/9.98G [00:58<01:26, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.02G/9.98G [00:58<01:26, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.03G/9.98G [00:58<01:25, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.04G/9.98G [00:59<01:25, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.05G/9.98G [00:59<01:25, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.06G/9.98G [00:59<01:25, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.07G/9.98G [00:59<01:24, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.08G/9.98G [00:59<01:24, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.09G/9.98G [00:59<01:24, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.10G/9.98G [01:00<01:24, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.11G/9.98G [01:00<01:25, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  41%|████▏     | 4.12G/9.98G [01:00<01:25, 68.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  41%|████▏     | 4.13G/9.98G [01:00<01:25, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.14G/9.98G [01:00<01:24, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.15G/9.98G [01:00<01:24, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.16G/9.98G [01:00<01:23, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.17G/9.98G [01:01<01:23, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.18G/9.98G [01:01<01:23, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.19G/9.98G [01:01<01:23, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.20G/9.98G [01:01<01:23, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.22G/9.98G [01:01<01:22, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.23G/9.98G [01:01<01:23, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.24G/9.98G [01:01<01:23, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.25G/9.98G [01:02<01:22, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.26G/9.98G [01:02<01:22, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.27G/9.98G [01:02<01:22, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.28G/9.98G [01:02<01:22, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.29G/9.98G [01:02<01:22, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.30G/9.98G [01:02<01:22, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.31G/9.98G [01:03<01:21, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.32G/9.98G [01:03<01:21, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.33G/9.98G [01:03<01:21, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▎     | 4.34G/9.98G [01:03<01:21, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▎     | 4.35G/9.98G [01:03<01:21, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▎     | 4.36G/9.98G [01:03<01:21, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.37G/9.98G [01:03<01:21, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.38G/9.98G [01:04<01:21, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.39G/9.98G [01:04<01:21, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.40G/9.98G [01:04<01:20, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.41G/9.98G [01:04<01:20, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.42G/9.98G [01:04<01:20, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.44G/9.98G [01:04<01:20, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.45G/9.98G [01:05<01:20, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.46G/9.98G [01:05<01:19, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.47G/9.98G [01:05<01:19, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.48G/9.98G [01:05<01:19, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.49G/9.98G [01:05<01:19, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 4.50G/9.98G [01:05<01:18, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 4.51G/9.98G [01:05<01:18, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 4.52G/9.98G [01:06<01:18, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 4.53G/9.98G [01:06<01:18, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.54G/9.98G [01:06<01:18, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.55G/9.98G [01:06<01:17, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.56G/9.98G [01:06<01:17, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.57G/9.98G [01:06<01:17, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.58G/9.98G [01:06<01:17, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.59G/9.98G [01:07<01:17, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.60G/9.98G [01:07<01:17, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.61G/9.98G [01:07<01:17, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▋     | 4.62G/9.98G [01:07<01:16, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  46%|████▋     | 4.63G/9.98G [01:07<01:16, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.65G/9.98G [01:07<01:16, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.66G/9.98G [01:08<01:16, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.67G/9.98G [01:08<01:16, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.68G/9.98G [01:08<01:15, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.69G/9.98G [01:08<01:15, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.70G/9.98G [01:08<01:15, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.71G/9.98G [01:08<01:15, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.72G/9.98G [01:09<01:54, 46.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.73G/9.98G [01:09<01:42, 51.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.74G/9.98G [01:09<01:34, 55.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.75G/9.98G [01:09<01:28, 58.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.76G/9.98G [01:09<01:24, 61.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.77G/9.98G [01:09<01:21, 63.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.78G/9.98G [01:10<01:19, 65.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.79G/9.98G [01:10<01:17, 66.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.80G/9.98G [01:10<01:16, 67.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.81G/9.98G [01:10<01:15, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.82G/9.98G [01:10<01:15, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.83G/9.98G [01:10<01:15, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  49%|████▊     | 4.84G/9.98G [01:11<01:14, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  49%|████▊     | 4.85G/9.98G [01:11<01:14, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.87G/9.98G [01:11<01:13, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.88G/9.98G [01:11<01:13, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.89G/9.98G [01:11<01:13, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.90G/9.98G [01:11<01:13, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.91G/9.98G [01:11<01:12, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.92G/9.98G [01:12<01:12, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.93G/9.98G [01:12<01:12, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.94G/9.98G [01:12<01:12, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.95G/9.98G [01:12<01:11, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.96G/9.98G [01:12<01:11, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.97G/9.98G [01:12<01:11, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.98G/9.98G [01:12<01:11, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 4.99G/9.98G [01:13<01:11, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 5.00G/9.98G [01:13<01:11, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 5.01G/9.98G [01:13<01:11, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 5.02G/9.98G [01:13<01:10, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 5.03G/9.98G [01:13<01:10, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.04G/9.98G [01:13<01:10, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.05G/9.98G [01:14<01:10, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.06G/9.98G [01:14<01:10, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.08G/9.98G [01:14<01:10, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.09G/9.98G [01:14<01:10, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.10G/9.98G [01:14<01:10, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.11G/9.98G [01:14<01:10, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  51%|█████▏    | 5.12G/9.98G [01:14<01:10, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  51%|█████▏    | 5.13G/9.98G [01:15<01:10, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.14G/9.98G [01:15<01:09, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.15G/9.98G [01:15<01:09, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.16G/9.98G [01:15<01:09, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.17G/9.98G [01:15<01:08, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.18G/9.98G [01:15<01:08, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.19G/9.98G [01:15<01:08, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.20G/9.98G [01:16<01:08, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.21G/9.98G [01:16<01:08, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.22G/9.98G [01:16<01:08, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.23G/9.98G [01:16<01:08, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.24G/9.98G [01:16<01:08, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.25G/9.98G [01:16<01:07, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.26G/9.98G [01:17<01:07, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.27G/9.98G [01:17<01:07, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.28G/9.98G [01:17<01:07, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.30G/9.98G [01:17<01:07, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.31G/9.98G [01:17<01:07, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.32G/9.98G [01:17<01:06, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.33G/9.98G [01:17<01:06, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.34G/9.98G [01:18<01:06, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▎    | 5.35G/9.98G [01:18<01:06, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▎    | 5.36G/9.98G [01:18<01:06, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.37G/9.98G [01:18<01:06, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.38G/9.98G [01:18<01:05, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.39G/9.98G [01:18<01:05, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.40G/9.98G [01:18<01:05, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.41G/9.98G [01:19<01:06, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.42G/9.98G [01:19<01:06, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.43G/9.98G [01:19<01:05, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.44G/9.98G [01:19<01:05, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.45G/9.98G [01:19<01:05, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.46G/9.98G [01:19<01:05, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.47G/9.98G [01:20<01:06, 68.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.48G/9.98G [01:20<01:05, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.49G/9.98G [01:20<01:05, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.51G/9.98G [01:20<01:04, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.52G/9.98G [01:20<01:04, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.53G/9.98G [01:20<01:04, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.54G/9.98G [01:20<01:03, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.55G/9.98G [01:21<01:03, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.56G/9.98G [01:21<01:04, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.57G/9.98G [01:21<01:04, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.58G/9.98G [01:21<01:03, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.59G/9.98G [01:21<01:03, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.60G/9.98G [01:21<01:02, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.61G/9.98G [01:22<01:02, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▋    | 5.62G/9.98G [01:22<01:02, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▋    | 5.63G/9.98G [01:22<01:02, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.64G/9.98G [01:22<01:02, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.65G/9.98G [01:22<01:02, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.66G/9.98G [01:22<01:02, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.67G/9.98G [01:22<01:02, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.68G/9.98G [01:23<01:02, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.69G/9.98G [01:23<01:02, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.70G/9.98G [01:23<01:02, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.71G/9.98G [01:23<01:02, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.73G/9.98G [01:23<01:01, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.74G/9.98G [01:23<01:01, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.75G/9.98G [01:23<01:01, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.76G/9.98G [01:24<01:00, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.77G/9.98G [01:24<01:00, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.78G/9.98G [01:24<01:00, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.79G/9.98G [01:24<01:00, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.80G/9.98G [01:24<00:59, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.81G/9.98G [01:24<00:59, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.82G/9.98G [01:25<00:59, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.83G/9.98G [01:25<00:59, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▊    | 5.84G/9.98G [01:25<00:59, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▊    | 5.85G/9.98G [01:25<00:59, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.86G/9.98G [01:25<00:59, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.87G/9.98G [01:25<00:59, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.88G/9.98G [01:25<00:59, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.89G/9.98G [01:26<00:58, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.90G/9.98G [01:26<00:58, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.91G/9.98G [01:26<00:58, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.92G/9.98G [01:26<00:58, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.93G/9.98G [01:26<00:57, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.95G/9.98G [01:26<00:57, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.96G/9.98G [01:27<00:57, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.97G/9.98G [01:27<00:57, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.98G/9.98G [01:27<00:57, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 5.99G/9.98G [01:27<00:57, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 6.00G/9.98G [01:27<00:57, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 6.01G/9.98G [01:27<00:56, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 6.02G/9.98G [01:27<00:56, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 6.03G/9.98G [01:28<00:56, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.04G/9.98G [01:28<00:56, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.05G/9.98G [01:28<00:56, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.06G/9.98G [01:28<00:56, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.07G/9.98G [01:28<00:56, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.08G/9.98G [01:28<00:55, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.09G/9.98G [01:28<00:55, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.10G/9.98G [01:29<00:55, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.11G/9.98G [01:29<00:55, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.12G/9.98G [01:29<00:55, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.13G/9.98G [01:29<00:55, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.14G/9.98G [01:29<00:54, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.16G/9.98G [01:29<00:54, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.17G/9.98G [01:30<00:54, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.18G/9.98G [01:30<00:54, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.19G/9.98G [01:30<00:54, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.20G/9.98G [01:30<00:54, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.21G/9.98G [01:30<00:54, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.22G/9.98G [01:30<00:54, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.23G/9.98G [01:31<01:21, 46.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.24G/9.98G [01:31<01:12, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.25G/9.98G [01:31<01:06, 55.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.26G/9.98G [01:31<01:02, 59.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.27G/9.98G [01:31<00:59, 62.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.28G/9.98G [01:31<00:57, 64.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.29G/9.98G [01:32<00:56, 65.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.30G/9.98G [01:32<00:55, 66.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.31G/9.98G [01:32<00:54, 67.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.32G/9.98G [01:32<00:53, 67.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.33G/9.98G [01:32<00:53, 68.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▎   | 6.34G/9.98G [01:32<00:52, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▎   | 6.35G/9.98G [01:32<00:52, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.36G/9.98G [01:33<00:52, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.38G/9.98G [01:33<00:51, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.39G/9.98G [01:33<00:51, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.40G/9.98G [01:33<00:51, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.41G/9.98G [01:33<00:51, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.42G/9.98G [01:33<00:51, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.43G/9.98G [01:34<00:51, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.44G/9.98G [01:34<00:50, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.45G/9.98G [01:34<00:50, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.46G/9.98G [01:34<00:50, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.47G/9.98G [01:34<00:50, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.48G/9.98G [01:34<00:50, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.49G/9.98G [01:34<00:50, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.50G/9.98G [01:35<00:50, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.51G/9.98G [01:35<00:49, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.52G/9.98G [01:35<00:49, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.53G/9.98G [01:35<00:49, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.54G/9.98G [01:35<00:49, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.55G/9.98G [01:35<00:49, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.56G/9.98G [01:36<00:48, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.57G/9.98G [01:36<00:48, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.59G/9.98G [01:36<00:48, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.60G/9.98G [01:36<00:48, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.61G/9.98G [01:36<00:48, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▋   | 6.62G/9.98G [01:36<00:48, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▋   | 6.63G/9.98G [01:36<00:48, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.64G/9.98G [01:37<00:47, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.65G/9.98G [01:37<00:47, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.66G/9.98G [01:37<00:47, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.67G/9.98G [01:37<00:47, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.68G/9.98G [01:37<00:47, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.69G/9.98G [01:37<00:47, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.70G/9.98G [01:37<00:47, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.71G/9.98G [01:38<00:47, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.72G/9.98G [01:38<00:46, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.73G/9.98G [01:38<00:46, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.74G/9.98G [01:38<00:46, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.75G/9.98G [01:38<00:46, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.76G/9.98G [01:38<00:46, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.77G/9.98G [01:39<00:46, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.78G/9.98G [01:39<00:45, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.79G/9.98G [01:39<00:45, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.81G/9.98G [01:39<00:45, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.82G/9.98G [01:39<00:45, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.83G/9.98G [01:39<00:45, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.84G/9.98G [01:39<00:45, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.85G/9.98G [01:40<00:44, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.86G/9.98G [01:40<00:44, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.87G/9.98G [01:40<00:44, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.88G/9.98G [01:40<00:44, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.89G/9.98G [01:40<00:44, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.90G/9.98G [01:40<00:44, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.91G/9.98G [01:40<00:44, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.92G/9.98G [01:41<00:43, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.93G/9.98G [01:41<00:43, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.94G/9.98G [01:41<00:43, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.95G/9.98G [01:41<00:43, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.96G/9.98G [01:41<00:43, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.97G/9.98G [01:41<00:42, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.98G/9.98G [01:42<00:42, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 6.99G/9.98G [01:42<00:42, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 7.00G/9.98G [01:42<00:42, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 7.01G/9.98G [01:42<00:42, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 7.03G/9.98G [01:42<00:42, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.04G/9.98G [01:42<00:42, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.05G/9.98G [01:42<00:42, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.06G/9.98G [01:43<00:42, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.07G/9.98G [01:43<00:41, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.08G/9.98G [01:43<00:41, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.09G/9.98G [01:43<00:41, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.10G/9.98G [01:43<00:41, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.11G/9.98G [01:43<00:41, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.12G/9.98G [01:43<00:40, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.13G/9.98G [01:44<00:40, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.14G/9.98G [01:44<00:40, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.15G/9.98G [01:44<00:40, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.16G/9.98G [01:44<00:40, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.17G/9.98G [01:44<00:40, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.18G/9.98G [01:44<00:40, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.19G/9.98G [01:45<00:40, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.20G/9.98G [01:45<00:39, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.21G/9.98G [01:45<00:39, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.22G/9.98G [01:45<00:39, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.24G/9.98G [01:45<00:39, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.25G/9.98G [01:45<00:39, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.26G/9.98G [01:45<00:39, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.27G/9.98G [01:46<00:38, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.28G/9.98G [01:46<00:38, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.29G/9.98G [01:46<00:38, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.30G/9.98G [01:46<00:38, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.31G/9.98G [01:46<00:38, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.32G/9.98G [01:46<00:38, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.33G/9.98G [01:46<00:37, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▎  | 7.34G/9.98G [01:47<00:37, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▎  | 7.35G/9.98G [01:47<00:37, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.36G/9.98G [01:47<00:37, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.37G/9.98G [01:47<00:37, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.38G/9.98G [01:47<00:37, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.39G/9.98G [01:47<00:37, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.40G/9.98G [01:48<00:36, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.41G/9.98G [01:48<00:37, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.42G/9.98G [01:48<00:36, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.43G/9.98G [01:48<00:36, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.44G/9.98G [01:48<00:36, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.46G/9.98G [01:48<00:36, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.47G/9.98G [01:48<00:35, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.48G/9.98G [01:49<00:35, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.49G/9.98G [01:49<00:35, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.50G/9.98G [01:49<00:35, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.51G/9.98G [01:49<00:35, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.52G/9.98G [01:49<00:35, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.53G/9.98G [01:49<00:35, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.54G/9.98G [01:50<00:34, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.55G/9.98G [01:50<00:34, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.56G/9.98G [01:50<00:34, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.57G/9.98G [01:50<00:34, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.58G/9.98G [01:50<00:34, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.59G/9.98G [01:50<00:34, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.60G/9.98G [01:50<00:33, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▋  | 7.61G/9.98G [01:51<00:33, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▋  | 7.62G/9.98G [01:51<00:33, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.63G/9.98G [01:51<00:33, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.64G/9.98G [01:51<00:33, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.65G/9.98G [01:51<00:33, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.67G/9.98G [01:51<00:33, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.68G/9.98G [01:51<00:32, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.69G/9.98G [01:52<00:32, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.70G/9.98G [01:52<00:32, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.71G/9.98G [01:52<00:32, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.72G/9.98G [01:52<00:32, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.73G/9.98G [01:52<00:32, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.74G/9.98G [01:52<00:32, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.75G/9.98G [01:53<00:32, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.76G/9.98G [01:53<00:31, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.77G/9.98G [01:53<00:31, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.78G/9.98G [01:53<00:31, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.79G/9.98G [01:53<00:31, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.80G/9.98G [01:53<00:31, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.81G/9.98G [01:53<00:30, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.82G/9.98G [01:54<00:30, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.83G/9.98G [01:54<00:30, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.84G/9.98G [01:54<00:30, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.85G/9.98G [01:54<00:30, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.86G/9.98G [01:54<00:30, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.87G/9.98G [01:54<00:30, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.89G/9.98G [01:54<00:30, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.90G/9.98G [01:55<00:45, 45.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.91G/9.98G [01:55<00:40, 51.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.92G/9.98G [01:55<00:37, 55.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.93G/9.98G [01:55<00:34, 59.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.94G/9.98G [01:55<00:32, 62.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.95G/9.98G [01:56<00:31, 64.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.96G/9.98G [01:56<00:30, 65.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.97G/9.98G [01:56<00:29, 66.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.98G/9.98G [01:56<00:29, 67.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 7.99G/9.98G [01:56<00:29, 68.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 8.00G/9.98G [01:56<00:28, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 8.01G/9.98G [01:57<00:28, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 8.02G/9.98G [01:57<00:28, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.03G/9.98G [01:57<00:28, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.04G/9.98G [01:57<00:27, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.05G/9.98G [01:57<00:27, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.06G/9.98G [01:57<00:28, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.07G/9.98G [01:57<00:28, 67.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.08G/9.98G [01:58<00:28, 67.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.10G/9.98G [01:58<00:27, 67.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.11G/9.98G [01:58<00:27, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████▏ | 8.12G/9.98G [01:58<00:27, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  81%|████████▏ | 8.13G/9.98G [01:58<00:26, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.14G/9.98G [01:58<00:26, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.15G/9.98G [01:59<00:26, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.16G/9.98G [01:59<00:26, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.17G/9.98G [01:59<00:25, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.18G/9.98G [01:59<00:25, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.19G/9.98G [01:59<00:25, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.20G/9.98G [01:59<00:25, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.21G/9.98G [01:59<00:25, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.22G/9.98G [02:00<00:25, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.23G/9.98G [02:00<00:25, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.24G/9.98G [02:00<00:24, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.25G/9.98G [02:00<00:24, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.26G/9.98G [02:00<00:24, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.27G/9.98G [02:00<00:24, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.28G/9.98G [02:00<00:24, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.29G/9.98G [02:01<00:24, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.30G/9.98G [02:01<00:24, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.32G/9.98G [02:01<00:24, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.33G/9.98G [02:01<00:23, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▎ | 8.34G/9.98G [02:01<00:23, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▎ | 8.35G/9.98G [02:01<00:23, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.36G/9.98G [02:02<00:23, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.37G/9.98G [02:02<00:23, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.38G/9.98G [02:02<00:23, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.39G/9.98G [02:02<00:22, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.40G/9.98G [02:02<00:22, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.41G/9.98G [02:02<00:22, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.42G/9.98G [02:02<00:22, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.43G/9.98G [02:03<00:22, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.44G/9.98G [02:03<00:22, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.45G/9.98G [02:03<00:22, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.46G/9.98G [02:03<00:22, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.47G/9.98G [02:03<00:22, 67.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.48G/9.98G [02:03<00:22, 67.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.49G/9.98G [02:04<00:21, 68.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.50G/9.98G [02:04<00:21, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.51G/9.98G [02:04<00:21, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.52G/9.98G [02:04<00:21, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.54G/9.98G [02:04<00:20, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.55G/9.98G [02:04<00:20, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.56G/9.98G [02:04<00:20, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.57G/9.98G [02:05<00:20, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.58G/9.98G [02:05<00:20, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.59G/9.98G [02:05<00:20, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.60G/9.98G [02:05<00:20, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▋ | 8.61G/9.98G [02:05<00:19, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▋ | 8.62G/9.98G [02:05<00:19, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.63G/9.98G [02:05<00:19, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.64G/9.98G [02:06<00:19, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.65G/9.98G [02:06<00:19, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.66G/9.98G [02:06<00:19, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.67G/9.98G [02:06<00:18, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.68G/9.98G [02:06<00:18, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.69G/9.98G [02:06<00:18, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.70G/9.98G [02:07<00:18, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.71G/9.98G [02:07<00:18, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.72G/9.98G [02:07<00:18, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.73G/9.98G [02:07<00:17, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.75G/9.98G [02:07<00:17, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.76G/9.98G [02:07<00:17, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.77G/9.98G [02:07<00:17, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.78G/9.98G [02:08<00:17, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.79G/9.98G [02:08<00:17, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.80G/9.98G [02:08<00:16, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.81G/9.98G [02:08<00:16, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.82G/9.98G [02:08<00:16, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.83G/9.98G [02:08<00:16, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▊ | 8.84G/9.98G [02:09<00:16, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▊ | 8.85G/9.98G [02:09<00:16, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.86G/9.98G [02:09<00:16, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.87G/9.98G [02:09<00:15, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.88G/9.98G [02:09<00:15, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.89G/9.98G [02:09<00:15, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.90G/9.98G [02:09<00:15, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.91G/9.98G [02:10<00:15, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.92G/9.98G [02:10<00:15, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.93G/9.98G [02:10<00:15, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.94G/9.98G [02:10<00:14, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.95G/9.98G [02:10<00:14, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.97G/9.98G [02:10<00:14, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.98G/9.98G [02:10<00:14, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 8.99G/9.98G [02:11<00:14, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.00G/9.98G [02:11<00:14, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.01G/9.98G [02:11<00:14, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.02G/9.98G [02:11<00:13, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.03G/9.98G [02:11<00:13, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.04G/9.98G [02:11<00:13, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.05G/9.98G [02:12<00:13, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.06G/9.98G [02:12<00:13, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.07G/9.98G [02:12<00:13, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.08G/9.98G [02:12<00:12, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.09G/9.98G [02:12<00:12, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.10G/9.98G [02:12<00:12, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████▏| 9.11G/9.98G [02:12<00:12, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████▏| 9.12G/9.98G [02:13<00:12, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.13G/9.98G [02:13<00:12, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.14G/9.98G [02:13<00:11, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.15G/9.98G [02:13<00:11, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.16G/9.98G [02:13<00:11, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.18G/9.98G [02:13<00:11, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.19G/9.98G [02:14<00:11, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.20G/9.98G [02:14<00:11, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.21G/9.98G [02:14<00:11, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.22G/9.98G [02:14<00:10, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.23G/9.98G [02:14<00:10, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.24G/9.98G [02:14<00:10, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.25G/9.98G [02:14<00:10, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.26G/9.98G [02:15<00:10, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.27G/9.98G [02:15<00:10, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.28G/9.98G [02:15<00:10, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.29G/9.98G [02:15<00:09, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.30G/9.98G [02:15<00:09, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.31G/9.98G [02:15<00:09, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.32G/9.98G [02:15<00:09, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▎| 9.33G/9.98G [02:16<00:09, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▎| 9.34G/9.98G [02:16<00:09, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.35G/9.98G [02:16<00:08, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.36G/9.98G [02:16<00:08, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.37G/9.98G [02:16<00:08, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.38G/9.98G [02:16<00:08, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.40G/9.98G [02:17<00:08, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.41G/9.98G [02:17<00:08, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.42G/9.98G [02:17<00:08, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.43G/9.98G [02:17<00:07, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.44G/9.98G [02:17<00:07, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.45G/9.98G [02:17<00:07, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.46G/9.98G [02:17<00:07, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.47G/9.98G [02:18<00:07, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.48G/9.98G [02:18<00:07, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.49G/9.98G [02:18<00:06, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.50G/9.98G [02:18<00:06, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.51G/9.98G [02:18<00:06, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.52G/9.98G [02:18<00:06, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.53G/9.98G [02:18<00:06, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.54G/9.98G [02:19<00:06, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.55G/9.98G [02:19<00:06, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.56G/9.98G [02:19<00:05, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.57G/9.98G [02:19<00:05, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.58G/9.98G [02:19<00:05, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.59G/9.98G [02:19<00:05, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.60G/9.98G [02:20<00:05, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.62G/9.98G [02:20<00:05, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.63G/9.98G [02:20<00:05, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.64G/9.98G [02:20<00:04, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.65G/9.98G [02:20<00:04, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.66G/9.98G [02:20<00:04, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.67G/9.98G [02:20<00:04, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.68G/9.98G [02:21<00:04, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.69G/9.98G [02:21<00:04, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.70G/9.98G [02:21<00:04, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.71G/9.98G [02:21<00:03, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.72G/9.98G [02:21<00:03, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.73G/9.98G [02:21<00:03, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.74G/9.98G [02:22<00:03, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.75G/9.98G [02:22<00:03, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.76G/9.98G [02:22<00:03, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.77G/9.98G [02:22<00:02, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.78G/9.98G [02:22<00:02, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.79G/9.98G [02:22<00:02, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.80G/9.98G [02:22<00:02, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.81G/9.98G [02:23<00:03, 46.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.83G/9.98G [02:23<00:02, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▊| 9.84G/9.98G [02:23<00:02, 55.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▊| 9.85G/9.98G [02:23<00:02, 59.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.86G/9.98G [02:23<00:01, 62.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.87G/9.98G [02:24<00:01, 64.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.88G/9.98G [02:24<00:01, 65.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.89G/9.98G [02:24<00:01, 66.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.90G/9.98G [02:24<00:01, 67.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.91G/9.98G [02:24<00:00, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.92G/9.98G [02:24<00:00, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.93G/9.98G [02:24<00:00, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.94G/9.98G [02:25<00:00, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.95G/9.98G [02:25<00:00, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.96G/9.98G [02:25<00:00, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 9.98G/9.98G [02:25<00:00, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading shards:  50%|█████     | 1/2 [05:07<05:07, 307.35s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like meta-llama/Llama-2-7b-hf is not the path to a directory containing a file named model-00002-of-00002.safetensors.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;31m# sending a valid response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[1;32m    288\u001b[0m                                      \" response\")\n",
      "\u001b[0;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    727\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;31m# sending a valid response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[1;32m    288\u001b[0m                                      \" response\")\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1233\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1600\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# 3. Exponential backoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     return http_backoff(\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: (ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 939b0c6a-3155-486a-b69c-73ceea444efe)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;31m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             raise LocalEntryNotFoundError(\n\u001b[0m\u001b[1;32m   1350\u001b[0m                 \u001b[0;34m\"An error happened while trying to locate the file on the Hub and we cannot find the requested files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-59c13f6fe073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpeft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m trained_model = peft.AutoPeftModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"nvdenisov2002/llama-longLoRA-v0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/peft/auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, adapter_name, is_trainable, config, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m             )\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mtokenizer_exists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    566\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_sharded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;31m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3000\u001b[0;31m             resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\n\u001b[0m\u001b[1;32m   3001\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m                 \u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# Load from URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m             cached_filename = cached_file(\n\u001b[0m\u001b[1;32m   1041\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mshard_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_missing_entries\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_connection_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;34mf\"We couldn't connect to '{HUGGINGFACE_CO_RESOLVE_ENDPOINT}' to load this file, couldn't find it in the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;34mf\" cached files and it looks like {path_or_repo_id} is not the path to a directory containing a file named\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like meta-llama/Llama-2-7b-hf is not the path to a directory containing a file named model-00002-of-00002.safetensors.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "import peft\n",
    "\n",
    "trained_model = peft.AutoPeftModelForCausalLM.from_pretrained(\n",
    "    \"nvdenisov2002/llama-longLoRA-v0\"\n",
    ")\n",
    "trained_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09fd47a4-8d5c-4f4c-b8a4-f19a57486b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T21:07:15.562235Z",
     "iopub.status.busy": "2024-05-07T21:07:15.561762Z",
     "iopub.status.idle": "2024-05-07T21:07:15.574648Z",
     "shell.execute_reply": "2024-05-07T21:07:15.573967Z",
     "shell.execute_reply.started": "2024-05-07T21:07:15.562212Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kek'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"kek\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fed19e-4a4f-43c4-86d7-1d96c623346b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575ee05-6565-4cd3-ae55-5c1fc773067a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0f395-cf25-4854-b81f-9449a18434f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98367386-5deb-4c2b-830f-a71d33985709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7695f-a135-46ef-b2e4-c9278ecc17e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2684fa1-0121-4341-a31b-6a3a9a3417fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T00:11:06.985810Z",
     "iopub.status.busy": "2024-05-07T00:11:06.985423Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin train\n",
      "Created config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Formatting inputs...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0125f16b565245f8be345bce97cb0749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Texts...:   0%|          | 0/7623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "\u001b[0;31mKernelOutOfMemory\u001b[0m",
     "evalue": "Kernel ran out of memory and has been restarted. If the restart fails, restart the kernel from the Kernel menu.\nIf the error persists, try choosing a different configuration or optimizing your code.",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "train(model_args, data_args, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c1fd8c-221b-4826-a4c8-44221c9b9598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T12:10:47.194114Z",
     "iopub.status.busy": "2024-05-07T12:10:47.193748Z",
     "iopub.status.idle": "2024-05-07T12:10:47.210249Z",
     "shell.execute_reply": "2024-05-07T12:10:47.209650Z",
     "shell.execute_reply.started": "2024-05-07T12:10:47.194093Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kek\n"
     ]
    }
   ],
   "source": [
    "print(\"kek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af2e48-f192-49b9-a03b-3c1b65642c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! torchrun --nproc_per_node=1 supervised-fine-tune.py  \\\n",
    "#         --model_name_or_path \"meta-llama/Llama-2-7b-hf\" \\\n",
    "#         --bf16 True \\\n",
    "#         --output_dir checkpoints \\\n",
    "#         --cache_dir cache \\\n",
    "#         --model_max_length 16384 \\\n",
    "#         --use_flash_attn True \\\n",
    "#         --train_data_path \"/home/jupyter/mnt/datasets/spbu_diplomas/russian_dataset/russian_dataset_train.csv\" \\\n",
    "#         --val_data_path \"/home/jupyter/mnt/datasets/spbu_diplomas/russian_dataset/russian_dataset_val.csv\" \\\n",
    "#         --low_rank_training True \\\n",
    "#         --num_train_epochs 5  \\\n",
    "#         --per_device_train_batch_size 1     \\\n",
    "#         --per_device_eval_batch_size 2     \\\n",
    "#         --gradient_accumulation_steps 8     \\\n",
    "#         --evaluation_strategy \"steps\"     \\\n",
    "#         --eval_steps 1 \\\n",
    "#         --logging_strategy \"steps\" \\\n",
    "#         --logging_steps 1 \\\n",
    "#         --save_strategy \"steps\"     \\\n",
    "#         --save_steps 98     \\\n",
    "#         --save_total_limit 2     \\\n",
    "#         --learning_rate 2e-5     \\\n",
    "#         --weight_decay 0.0     \\\n",
    "#         --warmup_steps 20     \\\n",
    "#         --lr_scheduler_type \"constant_with_warmup\"     \\\n",
    "#         --logging_steps 1     \\\n",
    "#         --deepspeed \"ds_configs/stage2.json\" \\\n",
    "#         --tf32 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16aee81-1562-4603-a4fa-c0813bd54cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
